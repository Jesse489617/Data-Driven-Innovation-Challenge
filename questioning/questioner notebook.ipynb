{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning a QA Model on Anime Fandom Data\n",
    "This notebook fine-tunes a `flan-t5-base` model on a custom anime QA dataset stored in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 919 examples [00:00, 15442.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "path = \"questions creation/data/qa_dataset.csv\"\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=path)\n",
    "dataset = dataset[\"train\"]\n",
    "dataset = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 827/827 [00:01<00:00, 497.04 examples/s]\n",
      "Map: 100%|██████████| 92/92 [00:00<00:00, 450.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def preprocess(example):\n",
    "    input_text = f\"question: {example['question']} context: {example['context']}\"\n",
    "    inputs = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    labels = tokenizer(example['answer'], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1242' max='4140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1242/4140 16:15 < 37:59, 1.27 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.074668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.062979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.062656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.063105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.063502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.066538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1242, training_loss=1.1376354960715713, metrics={'train_runtime': 976.7146, 'train_samples_per_second': 16.934, 'train_steps_per_second': 4.239, 'total_flos': 3397765982846976.0, 'train_loss': 1.1376354960715713, 'epoch': 6.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./anime_qa_model\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=20,  \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)], \n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "base_pipe = pipeline(\"text2text-generation\", model=model_checkpoint, tokenizer=model_checkpoint)\n",
    "fine_pipe = pipeline(\"text2text-generation\", model=\"./anime_qa_model/checkpoint-1242\", tokenizer=model_checkpoint)\n",
    "\n",
    "def truncate_prompt(prompt, tokenizer, max_length=512):\n",
    "    tokens = tokenizer(prompt, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    return tokenizer.decode(tokens[\"input_ids\"][0], skip_special_tokens=True)\n",
    "\n",
    "def compare_models_on_chunk(question, context, tokenizer, max_output_tokens=150):\n",
    "    prompt = f\"Answer the question based on the text below:\\n\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    prompt = truncate_prompt(prompt, tokenizer)\n",
    "\n",
    "    input_length = tokenizer(prompt, return_tensors='pt')['input_ids'].shape[1]\n",
    "    max_length = min(max_output_tokens, int(input_length * 0.5) + 20)\n",
    "\n",
    "    print(f\"\\n Question:\\n{question}\")\n",
    "    print(f\"\\n Context:\\n{context[:500]}{'...' if len(context) > 500 else ''}\")\n",
    "\n",
    "    try:\n",
    "        base_answer = base_pipe(prompt, max_length=max_length, do_sample=False)[0]['generated_text']\n",
    "        fine_answer = fine_pipe(prompt, max_length=max_length, do_sample=False)[0]['generated_text']\n",
    "\n",
    "        print(f\"\\n Base Model Answer:\\n{base_answer}\")\n",
    "        print(f\"\\n Fine-Tuned Model Answer:\\n{fine_answer}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question:\n",
      "What was hinata worried about?\n",
      "\n",
      " Context:\n",
      "Omnipotence ArcWhen Boruto was called in for his first mission in a long time, Hinata cried, worried that this time he might not come back, despite his assurance he would return. After he left, Himawari told her she could help Boruto if she became a shinobi, and asked if it would make her worry more instead. Hinata slaps her adopted son. While preparing for dinner with Naruto, she wished that their sons, Boruto and Kawaki, could join them. She asked Naruto how long their mission might take. Afte...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Base Model Answer:\n",
      "Boruto might not come back\n",
      "\n",
      " Fine-Tuned Model Answer:\n",
      "this time he might not come back\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"Omnipotence ArcWhen Boruto was called in for his first mission in a long time, Hinata cried, worried that this time he might not come back, despite his assurance he would return. After he left, Himawari told her she could help Boruto if she became a shinobi, and asked if it would make her worry more instead. Hinata slaps her adopted son. While preparing for dinner with Naruto, she wished that their sons, Boruto and Kawaki, could join them. She asked Naruto how long their mission might take. After leaving the house, Kawaki joined them, wanting to talk to Naruto. Kawaki expressed how much Naruto meant to him and how far he was willing to go to eliminate all the Ōtsutsuki, including Boruto. Hinata, hurt by hearing her own son say he would kill his brother, slapped him. Kawaki conceded that he might be insane for what he was willing to do, even if it meant killing his own brother. He then sent Naruto and Hinata away through a rift to prevent them from interfering, ready to bear their hatred and welcoming them to kill him when he was done. Naruto and Hinata were trapped inDaikokuten, suspended in time, unable to think, age, or require air or sustenance.\"\"\"\n",
    "\n",
    "question = \"What was hinata worried about?\"\n",
    "\n",
    "compare_models_on_chunk(question, context, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question:\n",
      "What color is Killua Hair?\n",
      "\n",
      " Context:\n",
      "Killua has spiky white hair, very pale skin, and blue eyes. His eyes change shape depending on his mood, narrowing and sharpening when he goes into assassination mode. Killua is fairly lean at the start of the series, due to constant physical conditioning and torture training he received when he was young. During the Chimera Ant Arc, he becomes more muscular and toned. In the 1999 anime adaptation, Killua's eyes are green. He is also often seen holding a green skateboard (turned yellow in the 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Base Model Answer:\n",
      "white\n",
      "\n",
      " Fine-Tuned Model Answer:\n",
      "white\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"Killua has spiky white hair, very pale skin, and blue eyes. His eyes change shape depending on his mood, narrowing and sharpening when he goes into assassination mode. Killua is fairly lean at the start of the series, due to constant physical conditioning and torture training he received when he was young. During the Chimera Ant Arc, he becomes more muscular and toned. In the 1999 anime adaptation, Killua's eyes are green. He is also often seen holding a green skateboard (turned yellow in the 2011 anime adaptation). Killua typically wears baggy clothing, usually a dark-coloredturtleneck. In the manga and 2011 anime adaptation, Killua wears long, baggy shorts, but the 1999 anime adaptation character design shortened them to end above his knees. Killua also wears purple boots, recolored brown and black in the 1999 anime adaptation. Killua's hair was longer as a child, almost to his shoulders. He wore a hoodie with his trademark blue coloring, grey pants, and shoes.\"\"\"\n",
    "\n",
    "question = \"What color is Killua Hair?\"\n",
    "\n",
    "compare_models_on_chunk(question, context, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "def scrape_fandom_page(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    title = soup.find('h1').text.strip()\n",
    "    content_div = soup.find('div', {'class': 'mw-parser-output'})\n",
    "    chunks, current_chunk, current_section_title = [], [], \"Introduction\"\n",
    "\n",
    "    for tag in content_div.find_all(['h2', 'h3', 'p']):\n",
    "        if tag.name in ['h2', 'h3']:\n",
    "            if current_chunk:\n",
    "                chunks.append({\n",
    "                    \"section\": current_section_title,\n",
    "                    \"text\": \" \".join(current_chunk)\n",
    "                })\n",
    "                current_chunk = []\n",
    "            current_section_title = tag.get_text(strip=True)\n",
    "        elif tag.name == 'p':\n",
    "            text = tag.get_text(strip=True)\n",
    "            if text:\n",
    "                current_chunk.append(text)\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append({\n",
    "            \"section\": current_section_title,\n",
    "            \"text\": \" \".join(current_chunk)\n",
    "        })\n",
    "\n",
    "    return {'title': title, 'url': url, 'chunks': chunks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_answers(question, retriever, top_k=3):\n",
    "    top_chunks = retriever.query(question, top_k=top_k)\n",
    "    context = \"\\n\".join(chunk[\"text\"] for chunk in top_chunks)\n",
    "\n",
    "    prompt = f\"Answer the question based on the text below:\\n\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    prompt = truncate_prompt(prompt, tokenizer)\n",
    "\n",
    "    input_tokens = tokenizer(prompt, return_tensors='pt')['input_ids'].shape[1]\n",
    "    max_output_tokens = min(200, int(input_tokens * 0.5) + 20)\n",
    "\n",
    "    base_answer = base_pipe(prompt, max_length=max_output_tokens, do_sample=False)[0]['generated_text']\n",
    "    fine_answer = fine_pipe(prompt, max_length=max_output_tokens, do_sample=False)[0]['generated_text']\n",
    "\n",
    "    print(\"\\n Question:\", question)\n",
    "    print(\"\\n Top Chunks Used:\")\n",
    "    for i, chunk in enumerate(top_chunks):\n",
    "        print(f\"\\nChunk #{i+1} - Section: {chunk['section']}\\n{chunk['text'][:300]}...\\n\")\n",
    "\n",
    "    print(\"\\n Base Model Answer:\\n\", base_answer)\n",
    "    print(\"\\n Fine-Tuned Model Answer:\\n\", fine_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    def __init__(self, chunks):\n",
    "        self.chunks = chunks\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.embeddings = self.model.encode([chunk['text'] for chunk in chunks], convert_to_tensor=True)\n",
    "\n",
    "    def query(self, question, top_k=3):\n",
    "        query_embedding = self.model.encode(question, convert_to_tensor=True)\n",
    "        scores = cosine_similarity([query_embedding.cpu().numpy()], self.embeddings.cpu().numpy())[0]\n",
    "        top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "        return [self.chunks[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question: What are Hinata's special abilities?\n",
      "\n",
      " Top Chunks Used:\n",
      "\n",
      "Chunk #1 - Section: Chakra Prowess and Control[]\n",
      "Hinata's Gentle Step: Twin Lion Fist using Hamura's chakra. From her special clan training, Hinata has advanced control of her chakra. In the anime, Hinata's additional training during Part I resulted in her ability to free herself from contraints[29]and manipulate nearby water sources, turning them...\n",
      "\n",
      "\n",
      "Chunk #2 - Section: Power[]\n",
      "Main article:PowerIn the anime, Hinata is part of a team of reinforcements sent toTonika Villageto help Team 7 in the fight againstKabuto Yakushi. Hinata attempts to stop theNine-Tailed Naruto Clonefrom taking chakra from Naruto, but she fails and is saved by Neji....\n",
      "\n",
      "\n",
      "Chunk #3 - Section: Video Games[]\n",
      "Hinata Hyūga is a playable character in the following video games: In later instalments of theClash of Ninjaseries, Hinata is playable in an \"awakened\" form. In this form, her clothes are similar to what she wore during theBikōchū Search Mission, though the form itself is not based on the events of ...\n",
      "\n",
      "\n",
      " Base Model Answer:\n",
      " In the anime, Hinata's additional training during Part I resulted in her ability to free herself from contraints[29]and manipulate nearby water sources, turning them intoprojectiles.[30]By Part II of the anime, Hinata's control has advanced enough to match amedical-nin's, for which reason she is assigned to help perform theFour-Corner Sealing Barrier.\n",
      "\n",
      " Fine-Tuned Model Answer:\n",
      " Hinata Hyga is a playable character in the following video games: In later instalments of the Clash of Ninjaseries, Hinata is playable in an \"awakened\" form. In this form, her clothes are similar to what she wore during the Bikch Search Mission, though the form itself is not based on the events of that arc. Awakened Hinata has a personality similar to Neji's during the Chnin Exams, arrogantly challenging opponents and boasting about the power of the main branch of the Hyga\n"
     ]
    }
   ],
   "source": [
    "url = \"https://naruto.fandom.com/wiki/Hinata_Hyūga\"\n",
    "result = scrape_fandom_page(url)\n",
    "retriever = Retriever(result['chunks'])\n",
    "\n",
    "# Ask any question you'd like:\n",
    "compare_model_answers(\"What are Hinata's special abilities?\", retriever)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anime-llm-assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
